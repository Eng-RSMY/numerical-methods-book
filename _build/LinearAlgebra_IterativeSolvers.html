---
redirect_from:
  - "/linearalgebra-iterativesolvers"
interact_link: content/LinearAlgebra_IterativeSolvers.ipynb
kernel_name: python3
kernel_path: content
has_widgets: false
title: |-
  Iterative Methods for Solving Linear Systems of Equations
pagenum: 16
prev_page:
  url: /LinearAlgebra_LU.html
next_page:
  url: 
suffix: .ipynb
search: x vec mathbf vdots bmatrix n k frac left right begin end ldots t ddots matrix b infty equation l vert c d m iteration j iterative rho e jacobi ldotsa systems method u convergence quad nn sum gauss seidel bar lim initial phantom triangular therefore s eigenvalue lambda linear follows guess align step ii matrices exists methods techniques technique converges involve process system qquad criterion using consider let ij where lower lu neq before eigenvalues convergent solving required very starts solve sequence rightarrow form starting reached norm example max previously called steps while tolerance middle python numpy implementation observations

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Iterative Methods for Solving Linear Systems of Equations</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Iterative techniques are rarely used for solving linear systems of small dimension because the computation time required for convergence usually exceeds that required for direct methods such as Gaussian elimination.  However, for very large systems, especially sparse systems (systems with a high percentage of 0 entries in the matrix), these iterative techniques can be very efficient in terms of computational run times and memory usage.</p>
<p>An iterative technique starts to solve the matrix equation $\mathbf{A}\vec{x} = \vec{b}$ starts with an initial approximation $\vec{x^0}$ and generates a sequence of vectors $\{\vec{x}^1,\vec{x}^2,\ldots, \vec{x}^N\}$ that converges to $\vec{x}$ as $N\rightarrow\infty$. These techniques involve a process that converts the system $\mathbf{A}\vec{x}=\vec{b}$ to an equivalent system of the form $\vec{x}=\mathbf{T}\vec{x}+\vec{c}$. The process then follows, for an initial guess $\vec{x}^0$</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align}
\vec{x}^1 &amp;= \mathbf{T}\vec{x}^0 + \vec{c}\\
\vec{x}^2 &amp;= \mathbf{T}\vec{x}^1 + \vec{c}\\
&amp;\phantom{=}\vdots\\
\vec{x}^N &amp;= \mathbf{T}\vec{x}^{N-1} + \vec{c}\\
\end{align}
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will stop the iteration when some convergence criterion has been reached. A popular convergence criterion uses the $L_{\infty}$norm. The $L_{\infty}$ norm is a metric that represents the greatest length or size of a vector or matrix component. Expressed mathematically,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{equation}
\vec{x} = [x_1, x_2, ..., x_n]^T
\end{equation}\begin{equation}
\Vert \vec{x}\Vert_{L_\infty} = \max \vert x_i\vert \quad \forall \quad i = 1, 2, ..., n
\end{equation}
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="An-example-using-an-iterative-method">An example using an iterative method<a class="anchor-link" href="#An-example-using-an-iterative-method"> </a></h2><p>Consider the system:</p>
$$
\begin{matrix} E_1: &amp; 10x_1 &amp; -x_2 &amp; +2x_3 &amp; &amp; =&amp; 6\\E_2: &amp; -x_1 &amp; +11x_2 &amp; -x_3 &amp; +3x_4 &amp; =&amp;25\\E_3: &amp; 2x_1 &amp; -x_2 &amp; + 10x_3 &amp; -x_4 &amp; =&amp;-11\\E_4: &amp;  &amp; -3x_2 &amp; -x_3 &amp; +8x_4 &amp; = &amp;15\end{matrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let us solve each equation, $E_j$, for the variable $x_j$.</p>
$$
\begin{matrix} E_1: &amp; x_1 =&amp;  &amp;\frac{1}{10}x_2&amp; - \frac{1}{5}x_3 &amp;  &amp; +\frac{3}{5}\\
E_2: &amp; x_2 = &amp;\frac{1}{11}x_1 &amp; &amp;\frac{1}{11}x_3 &amp; -\frac{3}{11}x_4 &amp; +\frac{25}{11}\\
E_3: &amp; x_3 = &amp;-\frac{1}{5}x_1 &amp; +\frac{1}{10}x_2 &amp; &amp; +\frac{1}{10}x_4 &amp; -\frac{11}{10}\\
E_4: &amp; x_4 = &amp; &amp; -\frac{3}{8}x_2 &amp; + \frac{1}{8}x_3 &amp; &amp; +\frac{15}{8} \end{matrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>using the notation introduced previously we have</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\vec{x}^1 = \begin{bmatrix} 0 &amp; \frac{1}{10} &amp; -\frac{1}{5} &amp; 0\\
\frac{1}{11} &amp; 0 &amp; \frac{1}{11} &amp; -\frac{3}{11}\\
-\frac{1}{5} &amp; \frac{1}{10} &amp; 0 &amp; \frac{1}{10}\\
0 &amp; -\frac{3}{8} &amp; \frac{1}{8} &amp; 0 \end{bmatrix}\vec{x}_0 + \begin{bmatrix}\frac{3}{5}\\\frac{25}{11}\\-\frac{11}{10}\\\frac{15}{8}\end{bmatrix},$$<p></p>
<p>for</p>
$$\vec{x}^0 = \begin{bmatrix}0\\0\\0\\0\end{bmatrix}, \qquad \vec{x}^1 = \begin{bmatrix}0.6000\\2.2727\\-1.1000\\1.8750\end{bmatrix}$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>we repeat this process until the desired convergence has been reached. This technique is called the Jacobi iterative method.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Psuedocode-for-Jacobi-iteration">Psuedocode for Jacobi iteration<a class="anchor-link" href="#Psuedocode-for-Jacobi-iteration"> </a></h3><p>For the matrix equation $\mathbf{A} \vec{x} = \vec{b}$ with an initial guess $\vec{x}^0$.</p>
\begin{equation}
A = \begin{bmatrix}a_{11}&amp;a_{12}&amp;...&amp;a_{1n}\\a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\a_{n1}&amp;...&amp;...&amp;a_{nn}\end{bmatrix}, \quad \vec{b} = \begin{bmatrix} b_{1} \\ b_{2} \\ \vdots \\ b_{n}\end{bmatrix}, \quad \vec{x}^{0} = \begin{bmatrix} x^0_{1} \\ x^0_{2} \\ \vdots \\ x^0_{n}\end{bmatrix}, 
\end{equation}<table>
<thead><tr>
<th style="text-align:right">Steps</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1.</td>
<td>While $\frac{\Vert \vec{x}_k - \vec{x}_{k-1} \Vert_{L_\infty}}{\Vert \vec{x} \Vert_{L_\infty}}&gt; tolerance$ do Step 2</td>
</tr>
<tr>
<td style="text-align:right">2.</td>
<td>$\phantom{--}$ For $i = 1, 2, \ldots, n$ do Step 3</td>
</tr>
<tr>
<td style="text-align:right">3.</td>
<td>$$\phantom{----} x^k_i = \left.\left( -\sum_{\substack{j=1 \\ i \ne j}}^n a_{ij} x^k_j  + b_i\right) \middle/ a_{ii} \right.$$</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Python/NumPy-implementation-of-Jacobi-iteration">Python/NumPy implementation of Jacobi iteration<a class="anchor-link" href="#Python/NumPy-implementation-of-Jacobi-iteration"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">jacobi</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
    
    <span class="n">T</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
        
        <span class="n">x_old</span>  <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        
        <span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_old</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">break</span>
            
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Observations-on-the-Jacobi-iterative-method">Observations on the Jacobi iterative method<a class="anchor-link" href="#Observations-on-the-Jacobi-iterative-method"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider a matrix $\mathbf{A}$, in which we split into three matrices, $\mathbf{D}$, $\mathbf{U}$, $\mathbf{L}$, where these matrices are diagonal, upper triangular, and lower triangular respectively.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
A = \begin{bmatrix}a_{11}&amp;a_{12}&amp;\ldots&amp;a_{1n}\\a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\a_{n1}&amp;\ldots&amp;\ldots&amp;a_{nn}\end{bmatrix}, D = \begin{bmatrix}a_{11}&amp;0&amp;\ldots&amp;0\\0&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\0&amp;\ldots&amp;\ldots&amp;a_{nn}\end{bmatrix}, \\
L = \begin{bmatrix}0&amp;0&amp;\ldots&amp;0\\-a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\-a_{n1}&amp;\ldots&amp;-a_{n(n-1)}&amp;0\end{bmatrix}, U = \begin{bmatrix}0&amp;-a_{12}&amp;\ldots&amp;-a_{1n}\\\vdots&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;-a_{(n-1)n}\\0&amp;\ldots&amp;\ldots&amp;0\end{bmatrix}
$$<p>If we let $\mathbf{A = D-L-U}$, then the matrix equation $\mathbf{A}\vec{x} = \vec{b}$ becomes</p>
\begin{equation}
\left(\mathbf{D-L-U}\right)\vec{x} = \vec{b} \quad \mathrm{or} \quad \mathbf{D}\vec{x} = \left(\mathbf{L+U}\right)\vec{x}+\vec{b}
\end{equation}
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>if $\mathbf{D}^{-1}$ exists, that implies $a_{jj} \neq 0$, then</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\vec{x} = \mathbf{D}^{-1}\left(\mathbf{L+U}\right)\vec{x}+\mathbf{D}^{-1}\vec{b}$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The results in the matrix form of the Jacobi iteration method</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{equation}
\vec{x}^k = \mathbf{D}^{-1}\left(\mathbf{L+U}\right)\vec{x}^{k-1}+\mathbf{D}^{-1}\vec{b}
\end{equation}
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that one requirement for the Jacobi iteration to work is for $a_{ii} \neq 0$. This may involve row exchanges before iterating for some linear systems.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gauss-Seidel-iteration:-An-improvement-to-the-Jacobi-iterative-method">Gauss-Seidel iteration: An improvement to the Jacobi iterative method<a class="anchor-link" href="#Gauss-Seidel-iteration:-An-improvement-to-the-Jacobi-iterative-method"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>During the Jacobi iteration we always use the components of $\vec{x}^{k-1}$ to compute $\vec{x}^{k}$ but for $i &gt; 1, {x}^{k}_1, \ldots, {x}^{k}_{i-1}$ are already computed and are most likely the best approximations of the real solution.  Therefore, we can calculate ${x}^{k}_i$ using the most recently calculated values when available. This technique is called <em>Gauss-Seidel iteration</em>. The pseudocode is as follows</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pseudocode-for-Gauss-Seidel-iteration">Pseudocode for Gauss-Seidel iteration<a class="anchor-link" href="#Pseudocode-for-Gauss-Seidel-iteration"> </a></h3><p>For the matrix equation $\mathbf{A} \vec{x} = \vec{b}$ with an initial guess $\vec{x}^0$.</p>
$$
A=\begin{bmatrix}a_{11}&amp;a_{12}&amp;\ldots&amp;a_{1n}\\a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\a_{n1}&amp;\ldots&amp;\ldots&amp;a_{nn}\end{bmatrix}, \bar{b} = \begin{bmatrix}b_1\\b_1\\\vdots\\b_n\end{bmatrix}, \bar{x}_0 = \begin{bmatrix}x^{0}_1\\x^{0}_2\\\vdots\\x^{0}_n\end{bmatrix}
$$<table>
<thead><tr>
<th style="text-align:right">Steps</th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1.</td>
<td style="text-align:left">While $\frac{\Vert\vec{x}^{k}-\vec{x}^{k-1}\Vert_{L_\infty}}{\Vert\bar{x}^{k}\Vert_{L_\infty}} &gt; tolerance$ do Step 2</td>
</tr>
<tr>
<td style="text-align:right">2.</td>
<td style="text-align:left">$\phantom{--}$ For $i = 1, 2, ..., n$ do Step 3</td>
</tr>
<tr>
<td style="text-align:right">3.</td>
<td style="text-align:left">$$\phantom{----} x^{k}_i = \left.\left(-\sum_{j=1}^{i-1}a_{ij}x^{k}_j-\sum_{j=i+1}^{n}a_{ij}x^{k-1}_j+b_i\right) \middle/ {a_{ii}}\right.$$</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Python/NumPy-implementation-of-Gauss-Seidel-iteration">Python/NumPy implementation of Gauss-Seidel iteration<a class="anchor-link" href="#Python/NumPy-implementation-of-Gauss-Seidel-iteration"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">gauss_seidel</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
    
    <span class="c1">#Iterate</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
        
        <span class="n">x_old</span>  <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        
        <span class="c1">#Loop over rows</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,:</span><span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):],</span> <span class="n">x_old</span><span class="p">[(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">):]))</span> <span class="o">/</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span> <span class="p">,</span><span class="n">i</span><span class="p">]</span>
            
        <span class="c1">#Stop condition </span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_old</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">break</span>
            
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Observations-on-the-Gauss-Seidel-iterative-method">Observations on the Gauss-Seidel iterative method<a class="anchor-link" href="#Observations-on-the-Gauss-Seidel-iterative-method"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider a matrix $\mathbf{A}$, in which we split into three matrices, $\mathbf{D, U, L}$, where these matrices are diagonal, upper triangular, and lower triangular respectively.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
A = \begin{bmatrix}a_{11}&amp;a_{12}&amp;\ldots&amp;a_{1n}\\a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\a_{n1}&amp;\ldots&amp;\ldots&amp;a_{nn}\end{bmatrix}, D = \begin{bmatrix}a_{11}&amp;0&amp;\ldots&amp;0\\0&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\0&amp;\ldots&amp;\ldots&amp;a_{nn}\end{bmatrix}, \\ L = \begin{bmatrix}0&amp;0&amp;\ldots&amp;0\\-a_{21}&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;\vdots\\-a_{n1}&amp;\ldots&amp;-a_{n(n-1)}&amp;0\end{bmatrix}, U = \begin{bmatrix}0&amp;-a_{12}&amp;\ldots&amp;-a_{1n}\\\vdots&amp;\ddots&amp; &amp;\vdots\\\vdots&amp; &amp;\ddots&amp;-a_{(n-1)n}\\0&amp;\ldots&amp;\ldots&amp;0\end{bmatrix}
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will leave, as an exercise for the student, the derivation, but the matrix equation for the Gauss-Seidel iteration method is as follows:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\vec{x}^k = \left(\mathbf{D-L}\right)^{-1}\mathbf{U}\vec{x}^{k-1}+\left(\mathbf{D-L}\right)^{-1}\vec{b}$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order for the lower triangular matrix $\mathbf{D-L}$ to be invertible it is necessary and sufficient for $a_{ii}\neq 0$. As before, this may involve row exchanges before iterating for some linear systems.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Convergence-of-iterative-methods">Convergence of iterative methods<a class="anchor-link" href="#Convergence-of-iterative-methods"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, a definition, the <em>spectral radius</em>, $\rho$, of matrix $\mathbf{A}$ is the maximum of the absolute values of the matrix $\mathbf{A}$'s eigenvalues.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\rho\left(\mathbf{A}\right) = \max\vert\lambda_i\vert$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>where the $\lambda_i$'s are the eigenvalues of $\mathbf{A}$.</p>
<p>Now, if $\rho\left(\mathbf{A}\right) &lt; 1$, then $(\mathbf{I-A})^{-1}$ exists, and</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$(\mathbf{I-A})^{-1} = \mathbf{I + A + A}^2 + \ldots = \sum_{j=0}^{\infty}\mathbf{A}^j$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can prove this, starting with the eigenvalue equation</p>
$$\mathbf{A}\vec{x} = \lambda \vec{x} \rightarrow (\mathbf{I-A})\vec{x} = (1-\lambda)\vec{x}$$<p>$\lambda$ is an eigenvalue of $\mathbf{A}$, exactly when $(1-\lambda)$ is an eigenvalue of $\mathbf{I-A}$. But $\vert\lambda\vert \leq \rho\left(\mathbf{A}\right) &lt; 1$, therefore $1$ cannot be an eigenvalue of $\mathbf{A}$, and $0$ cannot be an eigenvalue of $\mathbf{I-A}$. A matrix in which none of the eigenvalues are zero is always invertible, therefore $\left(\mathbf{I-A}\right)^{-1}$ exists. There also exists an identity which states that a matrix $\mathbf{A}$ is <em>convergent</em> if $\rho\left(\mathbf{A}\right) &lt; 1$, which implies that $\lim_{n\to\infty}\mathbf{A}^n\vec{x} = 0$ for all $\vec{x}$. Now, let</p>
$$\mathbf{S}_m = \mathbf{I} + \mathbf{A} + \mathbf{A}^2 + \ldots + \mathbf{A}^m$$<p>.</p>
<p>Then,</p>
$$\left(\mathbf{I-A}\right)\mathbf{S}_m = \left(1+\mathbf{A+A}^2+\ldots + \mathbf{A}^m)-(\mathbf{A+A}^2+\ldots+\mathbf{A}^{m+1}\right)=\left(\mathbf{I-A}^{m+1}\right).$$<p>Since $\mathbf{A}$ is convergent, we can see that by taking the limit of both sides</p>
$$\lim_{m\to\infty}\left(\mathbf{I-A}\right)\mathbf{S}_m=\lim_{m\to\infty}\left(\mathbf{I-A}^{m+1}\right)=\mathbf{I},$$<p>therefore</p>
$$\left(\mathbf{I-A}\right)^{-1} = \lim_{m\to\infty}\mathbf{S}_m = \sum_{j=0}^{\infty}\mathbf{A}^j$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now for any $\bar{x}_0\in\mathbb{R}^n$ the sequence $\{\bar{x}^k\}_{k=0}^{\infty}$ computed by</p>
$$\vec{x}^k = \mathbf{T}\vec{x}^{k-1}+\vec{c},$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>for each $k\geq 1$</p>
<p>Converges to the unique solution of $\vec{x} = \mathbf{T} \vec{x} + \vec{c}$ if and only if $\rho \left(\mathbf{T}\right) &lt; 1$.  We can prove this, first we will assume that $\rho\left(T\right) &lt; 1$. Then,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align}
\vec{x}^k &amp;= \mathbf{T}\vec{x}^{k-1}+\vec{c} \\
&amp;= \mathbf{T}\left(\mathbf{T}\vec{x}^{k-2} + \vec{c}\right) + \vec{c} \\
&amp;= \mathbf{T}^2 \vec{x}^{k-2}+\left(\mathbf{T-I}\right)\vec{c} \\
&amp;\vdots \\
&amp;= \mathbf{T}^k \vec{x}^0 + (\mathbf{T}^{k-1} + \ldots + \mathbf{T + I})\bar{c}
\end{align}
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since $\rho\left(\mathbf{T}\right) &lt; 1$, $\mathbf{T}$ is convergent, then from what we learned previously, it follows</p>
$$\lim_{k\to\infty}\vec{x}^k = \lim_{k\to\infty}\mathbf{T}^k\vec{x}^0 + \left(\sum_{j=0}^{\infty}\mathbf{T}^j\right)\vec{c} = \mathbf{0} + \left(\mathbf{I-T}\right)^{-1} \vec{c}$$<p>Therefore, $\vec{x}^k$ converges to $\left(\mathbf{I-T}\right)^{-1}\vec{c}$.</p>

</div>
</div>
</div>
</div>

 


    </main>
    